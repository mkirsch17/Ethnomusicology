{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "infolder = './data/'\n",
    "infile = infolder + 'default_features_1059_tracks_with_continents.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n, h, activation):\n",
    "    '''Build neural network model'''\n",
    "    \n",
    "    # Number of nodes per layer\n",
    "    s = []\n",
    "    s.append(len(X_train[0]))\n",
    "\n",
    "    for ii in range(0, n-2):\n",
    "        s.append(h)\n",
    "\n",
    "    s.append(num_classes)\n",
    "\n",
    "    # Initialize empty model\n",
    "    model = torch.nn.Sequential()\n",
    "\n",
    "    # For each layer, add to existing model\n",
    "    for ii, s_i in enumerate(s[:-1]): \n",
    "        \n",
    "        # If activation identity, don't add any acivation\n",
    "        if activation == 'identity':\n",
    "            model = torch.nn.Sequential(\n",
    "                model,\n",
    "                torch.nn.Linear(s_i, s[ii+1])\n",
    "            )\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # If any other activation, add the according activation\n",
    "        if activation == 'relu':\n",
    "            layer_activation = torch.nn.ReLU()\n",
    "\n",
    "        if activation == 'sigmoid':\n",
    "            layer_activation = torch.nn.Sigmoid()\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            layer_activation = torch.nn.Tanh()\n",
    "\n",
    "        # If it's the last layer, just add Sigmoid activation\n",
    "        if ii == len(s) - 2:\n",
    "            \n",
    "            # Update model\n",
    "            model = torch.nn.Sequential(\n",
    "                model,\n",
    "                torch.nn.Linear(s_i, s[ii+1]),\n",
    "                torch.nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Update model\n",
    "            model = torch.nn.Sequential(\n",
    "                model,\n",
    "                torch.nn.Linear(s_i, s[ii+1]),\n",
    "                layer_activation\n",
    "            )\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, learning_rate, loss_fn):\n",
    "    \n",
    "    # Train neural network model\n",
    "    for t in range(2001):\n",
    "\n",
    "        # Compute outputs of model\n",
    "        y_pred = model(X_train)\n",
    "\n",
    "        # Compute loss function of model\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        if t % 100 == 0:\n",
    "            #print(t, loss.item())\n",
    "            pass\n",
    "\n",
    "        # Zero the gradients before running the backward pass.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "        # parameters of the model\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights using gradient descent\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, n, h):\n",
    "    \n",
    "    # Run model on training data\n",
    "    y_train_pred_raw = model(X_train).tolist()\n",
    "    y_train_pred = [val.index(max(val)) for val in y_train_pred_raw]\n",
    "\n",
    "    # Run model on test data \n",
    "    y_test_pred_raw = model(X_test).tolist()\n",
    "    y_test_pred = [val.index(max(val)) for val in y_test_pred_raw]\n",
    "    \n",
    "    # Determine accuracy on training data\n",
    "    training_pred_bool = [y_train_pred[ii] == y_train[ii] for ii in range(0, len(y_train))]\n",
    "    training_acc = int(sum(training_pred_bool)) / len(y_train)\n",
    "\n",
    "    # Determine accuracy on test data\n",
    "    test_pred_bool = [y_test_pred[ii] == y_test[ii] for ii in range(0, len(y_test))]\n",
    "    test_acc = int(sum(test_pred_bool)) / len(y_test)\n",
    "\n",
    "    #print('NN (n=%s, size=%s):\\nTraining error: %.1f%%\\nTest error: %.1f%%' % (n, h, training_error*100, test_error*100))\n",
    "    \n",
    "    return(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into dataframe\n",
    "df = pd.read_csv(infile)\n",
    "\n",
    "# Remove old index, latitude, and longitude columns from data\n",
    "df.drop(columns=['Unnamed: 0', 'lat', 'long'], inplace=True)\n",
    "\n",
    "# Determine how many classes exist\n",
    "num_classes = len(set(df.continent.tolist()))\n",
    "\n",
    "# Map classifications from strings to numerical values\n",
    "df.replace({'Africa': 0, 'Asia': 1, 'Europe': 2, 'Oceania': 3, 'South America': 4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input X and output y\n",
    "X = np.array(df.iloc[:, 1:-2])\n",
    "y = np.array(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of layers to test\n",
    "n_vals = [3, 4, 5]\n",
    "\n",
    "# Hidden layer sizes to test\n",
    "h_vals = [5, 25, 50, 75]\n",
    "\n",
    "# Learning rate values to test\n",
    "learning_rate_vals = [1, 10, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of activation to use\n",
    "# Choices (enter exactly): sigmoid, tanh (hyperbolic tangent), relu (rectifier linear), identity\n",
    "activation = 'relu'\n",
    "\n",
    "# K-fold cross validation\n",
    "k = 5\n",
    "\n",
    "# Initialize dictionary to contain test accuracy for every hyperparameter combination\n",
    "dict_combo_acc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, h=5, learning_rate=1:\n",
      "Test accuracy: 52.2%\n",
      "\n",
      "n=3, h=5, learning_rate=10:\n",
      "Test accuracy: 49.2%\n",
      "\n",
      "n=3, h=5, learning_rate=25:\n",
      "Test accuracy: 50.0%\n",
      "\n",
      "n=3, h=25, learning_rate=1:\n",
      "Test accuracy: 54.8%\n",
      "\n",
      "n=3, h=25, learning_rate=10:\n",
      "Test accuracy: 57.3%\n",
      "\n",
      "n=3, h=25, learning_rate=25:\n",
      "Test accuracy: 56.0%\n",
      "\n",
      "n=3, h=50, learning_rate=1:\n",
      "Test accuracy: 57.3%\n",
      "\n",
      "n=3, h=50, learning_rate=10:\n",
      "Test accuracy: 58.6%\n",
      "\n",
      "n=3, h=50, learning_rate=25:\n",
      "Test accuracy: 55.3%\n",
      "\n",
      "n=3, h=75, learning_rate=1:\n",
      "Test accuracy: 61.1%\n",
      "\n",
      "n=3, h=75, learning_rate=10:\n",
      "Test accuracy: 59.2%\n",
      "\n",
      "n=3, h=75, learning_rate=25:\n",
      "Test accuracy: 57.3%\n",
      "\n",
      "n=4, h=5, learning_rate=1:\n",
      "Test accuracy: 46.9%\n",
      "\n",
      "n=4, h=5, learning_rate=10:\n",
      "Test accuracy: 46.6%\n",
      "\n",
      "n=4, h=5, learning_rate=25:\n",
      "Test accuracy: 47.8%\n",
      "\n",
      "n=4, h=25, learning_rate=1:\n",
      "Test accuracy: 55.4%\n",
      "\n",
      "n=4, h=25, learning_rate=10:\n",
      "Test accuracy: 54.2%\n",
      "\n",
      "n=4, h=25, learning_rate=25:\n",
      "Test accuracy: 55.1%\n",
      "\n",
      "n=4, h=50, learning_rate=1:\n",
      "Test accuracy: 56.0%\n",
      "\n",
      "n=4, h=50, learning_rate=10:\n",
      "Test accuracy: 57.2%\n",
      "\n",
      "n=4, h=50, learning_rate=25:\n",
      "Test accuracy: 55.1%\n",
      "\n",
      "n=4, h=75, learning_rate=1:\n",
      "Test accuracy: 55.4%\n",
      "\n",
      "n=4, h=75, learning_rate=10:\n",
      "Test accuracy: 56.0%\n",
      "\n",
      "n=4, h=75, learning_rate=25:\n",
      "Test accuracy: 58.5%\n",
      "\n",
      "n=5, h=5, learning_rate=1:\n",
      "Test accuracy: 38.9%\n",
      "\n",
      "n=5, h=5, learning_rate=10:\n",
      "Test accuracy: 46.5%\n",
      "\n",
      "n=5, h=5, learning_rate=25:\n",
      "Test accuracy: 38.9%\n",
      "\n",
      "n=5, h=25, learning_rate=1:\n",
      "Test accuracy: 49.1%\n",
      "\n",
      "n=5, h=25, learning_rate=10:\n",
      "Test accuracy: 53.2%\n",
      "\n",
      "n=5, h=25, learning_rate=25:\n",
      "Test accuracy: 40.4%\n",
      "\n",
      "n=5, h=50, learning_rate=1:\n",
      "Test accuracy: 48.3%\n",
      "\n",
      "n=5, h=50, learning_rate=10:\n",
      "Test accuracy: 55.5%\n",
      "\n",
      "n=5, h=50, learning_rate=25:\n",
      "Test accuracy: 34.4%\n",
      "\n",
      "n=5, h=75, learning_rate=1:\n",
      "Test accuracy: 46.8%\n",
      "\n",
      "n=5, h=75, learning_rate=10:\n",
      "Test accuracy: 56.2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each number of layers to test\n",
    "for n in n_vals:\n",
    "    \n",
    "    # For each hidden layer size to test\n",
    "    for h in h_vals:\n",
    "        \n",
    "        # For each learning rate to test\n",
    "        for learning_rate in learning_rate_vals:\n",
    "            \n",
    "            # \"Name\" of hyperparameter combination (n-h-learning_rate)\n",
    "            combo = '%s-%s-%s' % (n, h, learning_rate)\n",
    "\n",
    "            # Set-up K-fold CV\n",
    "            kf = KFold(n_splits=k)\n",
    "\n",
    "            # Initialize list to hold testing accuracy for current hyperparameter combination\n",
    "            all_test_accs = []\n",
    "\n",
    "            # Build and evaluate model for these hyperparameter combinations k times\n",
    "            for ii, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "                # Split data into training and testing data\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                # Convert testing and training data to tensors\n",
    "                X_train = torch.from_numpy(X_train).float()\n",
    "                y_train = torch.from_numpy(y_train)\n",
    "                X_test = torch.from_numpy(X_test).float()\n",
    "                y_test = torch.from_numpy(y_test)\n",
    "\n",
    "                # Build neural network model\n",
    "                model = build_model(n, h, activation)\n",
    "\n",
    "                # Loss function\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "                # Train model\n",
    "                train_model(model, X_train, y_train, learning_rate, loss_fn)\n",
    "\n",
    "                # Evaluate model's performance\n",
    "                test_acc = evaluate_model(model, X_train, y_train, X_test, y_test, n, h)\n",
    "\n",
    "                # Append test accuracy to list\n",
    "                all_test_accs.append(test_acc)\n",
    "\n",
    "            # Calculate average test accuracy for this hyperparameter combination across k runs\n",
    "            avg_test_acc = sum(all_test_accs) / len(all_test_accs)\n",
    "            print('n=%s, h=%s, learning_rate=%s:\\nTest accuracy: %.1f%%\\n' % (n, h, learning_rate, (avg_test_acc*100)))\n",
    "\n",
    "            dict_combo_acc[combo] = avg_test_acc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter combination with the highest test accuracy\n",
    "best_combo = {key: value for key, value in dict_combo_acc.items() if value == max(dict_combo_acc.values())}\n",
    "\n",
    "n_best = list(best_combo.keys())[0].split('-')[0]\n",
    "h_best = list(best_combo.keys())[0].split('-')[1]\n",
    "learning_rate_best = list(best_combo.keys())[0].split('-')[2]\n",
    "test_acc_best = list(best_combo.values())[0]\n",
    "\n",
    "\n",
    "print('The most accurate model, with %.1f%% accuracy, has %s layers, %s nodes per hidden layer, and a learning rate of %s.' % \n",
    "     (test_acc_best*100, n_best, h_best, learning_rate_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
